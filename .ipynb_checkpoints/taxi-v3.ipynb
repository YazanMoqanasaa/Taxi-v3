{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b95732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "taxi_run 0 Total Rewards: -1242 Steps: 561\n",
      "taxi_run 100 Total Rewards: -343 Steps: 256\n",
      "taxi_run 200 Total Rewards: -289 Steps: 229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#Red — 0 , Green — 1, Yellow — 2, and Blue — 3 for pick up\n",
    "streets = gym.make(\"Taxi-v3\").env #New versions keep getting released; if -v3 doesn't work, try -v2 or -v4\n",
    "\n",
    "\n",
    "##Red — 0 , Green — 1, Yellow — 2, and Blue — 3 for pick up\n",
    "#Each state is defined by a 4 entries tuple: （taxi_row, taxi_col, passenger_location, destination)\n",
    "initial_state = streets.encode(2, 3, 2, 0)\n",
    "streets.s = initial_state\n",
    "streets.render()\n",
    "\n",
    "#State Space:  25 possible taxi positions, 5 possible locations of the passenger\n",
    "# 25*5*4 = 500 \n",
    "\n",
    "\n",
    "#Action space:6 --> N,S,E,W, DROP-OFF, PICKUP\n",
    "#Rewards: CORRECT FINAL DEST. +20, STEP -1, INCORRECT PICK/DROP -10\n",
    "\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n]) # 500 , 6\n",
    "#q_table.size\n",
    "# a 2D array that represent every possible state and action in the virtual space and initialize all of them to 0\n",
    "total_reward_G = 0\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.5\n",
    "exploration = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "for taxi_run in range(epochs): #Start training (the agent plays the number of epochs)\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    total_reward_G = 0\n",
    "    steps=0\n",
    "    while not done:#each epoch/play contains this number of actions, starting from pickup a passenger until drop-off\n",
    "        steps +=1\n",
    "        random_value = random.uniform(0, 1)\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() # Explore a random action\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Return the action with the highest q-value\n",
    "            \n",
    "        next_state, reward, done, info = streets.step(action) # Do the above action\n",
    "        \n",
    "        prev_q = q_table[state, action]\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        # see RL-2 PPT file --- slide# 5\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        total_reward_G += reward\n",
    "        q_table[state, action] = new_q\n",
    "        #streets.render()        \n",
    "        state = next_state\n",
    "\n",
    "    if (taxi_run) % 100 ==0:   \n",
    "         print('taxi_run {} Total Rewards: {} Steps: {}'.format(taxi_run,total_reward_G,steps))\n",
    "         #streets.render() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634988cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number 10 Step 11\n",
      "+---------+\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n",
      "step=9999\n",
      "Discount_factor = 0.9\n",
      "Average Rewards: -9.6149\n",
      "Average Steps: 22.865\n",
      "Average Trip Length: 13.7\n",
      "Comparison of discount factors:\n",
      "Discount_factor = 0.3\tDiscount_factor = 0.5\tDiscount_factor = 0.9\n",
      "REWARD\t -25.0493\t\t\t-17.2015\t\t\t-9.6149\n",
      "STEPS\t35.2061\t\t\t29.2222\t\t\t22.865\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env\n",
    "streets.render()\n",
    "\n",
    "discount_factors = [0.3, 0.5, 0.9]\n",
    "avg_rewards = []\n",
    "avg_steps = []\n",
    "\n",
    "for discount_factor in discount_factors:\n",
    "    q_table = np.zeros([streets.observation_space.n, streets.action_space.n])  # 500, 6\n",
    "    total_rewards = []\n",
    "    total_steps = []\n",
    "\n",
    "    epochs = 10000\n",
    "\n",
    "    for taxi_run in range(epochs):\n",
    "        state = streets.reset()\n",
    "        done = False\n",
    "        total_reward_G = 0\n",
    "        steps = 0\n",
    "\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            random_value = random.uniform(0, 1)\n",
    "\n",
    "            if random_value < exploration:\n",
    "                action = streets.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "\n",
    "            next_state, reward, done, info = streets.step(action)\n",
    "\n",
    "            prev_q = q_table[state, action]\n",
    "            next_max_q = np.max(q_table[next_state])\n",
    "            new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "            q_table[state, action] = new_q\n",
    "            state = next_state\n",
    "\n",
    "            total_reward_G += reward\n",
    "\n",
    "        if taxi_run % 1000 == 0:\n",
    "            print('Taxi Run {} Total Rewards: {} Steps: {}'.format(taxi_run, total_reward_G, steps))\n",
    "\n",
    "        total_rewards.append(total_reward_G)\n",
    "        total_steps.append(steps)\n",
    "\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    avg_step = np.mean(total_steps)\n",
    "\n",
    "    avg_rewards.append(avg_reward)\n",
    "    avg_steps.append(avg_step)\n",
    "\n",
    "    lengths = []\n",
    "    for tripnum in range(1, 11):\n",
    "        state = streets.reset()\n",
    "        done = False\n",
    "        trip_length = 0\n",
    "\n",
    "        while not done and trip_length < 25:\n",
    "            action = np.argmax(q_table[state])\n",
    "            next_state, reward, done, info = streets.step(action)\n",
    "            clear_output(wait=True)\n",
    "            print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "            print(streets.render(mode='ansi'))\n",
    "            sleep(.2)\n",
    "            state = next_state\n",
    "            trip_length += 1\n",
    "        lengths.append(trip_length)\n",
    "\n",
    "    avg_len = np.mean(lengths)\n",
    "    print(f\"step={taxi_run}\")\n",
    "    print(f\"Discount_factor = {discount_factor}\")\n",
    "    print(f\"Average Rewards: {avg_reward}\")\n",
    "    print(f\"Average Steps: {avg_step}\")\n",
    "    print(f\"Average Trip Length: {avg_len}\")\n",
    "\n",
    "print(\"Comparison of discount factors:\")\n",
    "print(\"Discount_factor = 0.3\\tDiscount_factor = 0.5\\tDiscount_factor = 0.9\")\n",
    "print(f\"REWARD\\t {avg_rewards[0]}\\t\\t\\t{avg_rewards[1]}\\t\\t\\t{avg_rewards[2]}\")\n",
    "print(f\"STEPS\\t{ avg_steps[0]}\\t\\t\\t{avg_steps[1]}\\t\\t\\t{avg_steps[2]}\")\n",
    "if taxi_run % 1000 == 0:\n",
    "    print('Taxi Run {} Total Rewards: {} Steps: {}'.format(taxi_run, total_reward_G, steps))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12faa45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
